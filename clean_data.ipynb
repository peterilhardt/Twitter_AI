{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from clean_tweets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_year</th>\n",
       "      <th>tweet_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1161789559715196928</td>\n",
       "      <td>Once you combine this gigantic amorphous mass ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1161789531328319488</td>\n",
       "      <td>Do you believe in the power of #AI education? ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1161789508771336195</td>\n",
       "      <td>RT MikeQuindazzi: 7 #AI terms in the #Futureof...</td>\n",
       "      <td>2019</td>\n",
       "      <td>Bordeaux, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1161789506426671104</td>\n",
       "      <td>What if technology could help you be anywhere ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>Santiago, Chile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1161789505889820672</td>\n",
       "      <td>RT MikeQuindazzi: #BigData sets unlocking $45 ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>Bordeaux, France</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                                         tweet_text  \\\n",
       "0  1161789559715196928  Once you combine this gigantic amorphous mass ...   \n",
       "1  1161789531328319488  Do you believe in the power of #AI education? ...   \n",
       "2  1161789508771336195  RT MikeQuindazzi: 7 #AI terms in the #Futureof...   \n",
       "3  1161789506426671104  What if technology could help you be anywhere ...   \n",
       "4  1161789505889820672  RT MikeQuindazzi: #BigData sets unlocking $45 ...   \n",
       "\n",
       "   tweet_year    tweet_location  \n",
       "0        2019               NaN  \n",
       "1        2019               NaN  \n",
       "2        2019  Bordeaux, France  \n",
       "3        2019   Santiago, Chile  \n",
       "4        2019  Bordeaux, France  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('tweets_2019_large_df_reduced.pickle', 'rb') as f:\n",
    "    large_2019 = pickle.load(f)\n",
    "large_2019 = large_2019.rename(columns = {'year': 'tweet_year', 'location': 'tweet_location', \n",
    "                                          'text': 'tweet_text'})\n",
    "large_2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_year</th>\n",
       "      <th>tweet_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>544845252</td>\n",
       "      <td>Anyone involved in artificial intelligence wor...</td>\n",
       "      <td>2007</td>\n",
       "      <td>Malham Close, Crawley, West Su</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>532130162</td>\n",
       "      <td>読書中 Paradigms of Artificial Intelligence Progr...</td>\n",
       "      <td>2007</td>\n",
       "      <td>JP (Japan, Japan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>531926162</td>\n",
       "      <td>Update on geekgirl LOVE AND SEX WITH ROBOTS: I...</td>\n",
       "      <td>2007</td>\n",
       "      <td>Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>524153882</td>\n",
       "      <td>\"A.I. Artificial Intelligence\" a Speilberg mov...</td>\n",
       "      <td>2007</td>\n",
       "      <td>Barsoom!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>523822582</td>\n",
       "      <td>Paradigms of Artificial Intelligence Programmi...</td>\n",
       "      <td>2007</td>\n",
       "      <td>JP (Japan, Japan)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                         tweet_text  tweet_year  \\\n",
       "0  544845252  Anyone involved in artificial intelligence wor...        2007   \n",
       "1  532130162  読書中 Paradigms of Artificial Intelligence Progr...        2007   \n",
       "2  531926162  Update on geekgirl LOVE AND SEX WITH ROBOTS: I...        2007   \n",
       "3  524153882  \"A.I. Artificial Intelligence\" a Speilberg mov...        2007   \n",
       "4  523822582  Paradigms of Artificial Intelligence Programmi...        2007   \n",
       "\n",
       "                   tweet_location  \n",
       "0  Malham Close, Crawley, West Su  \n",
       "1               JP (Japan, Japan)  \n",
       "2                       Melbourne  \n",
       "3                        Barsoom!  \n",
       "4               JP (Japan, Japan)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('tweets_all_years_df_reduced.pickle', 'rb') as f:\n",
    "    all_years = pickle.load(f)\n",
    "all_years = all_years.rename(columns = {'year': 'tweet_year', 'location': 'tweet_location', \n",
    "                                        'text': 'tweet_text'})\n",
    "all_years.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Anyone involved in artificial intelligence wor...\n",
       "1     読書中 Paradigms of Artificial Intelligence Progr...\n",
       "2     Update on geekgirl LOVE AND SEX WITH ROBOTS: I...\n",
       "3     \"A.I. Artificial Intelligence\" a Speilberg mov...\n",
       "4     Paradigms of Artificial Intelligence Programmi...\n",
       "5     @moltz: chill it, dude. Your twirly brain wave...\n",
       "6     Leadership and Artificial Intelligence: Two ne...\n",
       "7     Class: Intro to Artificial Intelligence and Co...\n",
       "8     aibits: Artificial Intelligence for Advanced P...\n",
       "9     Most excellent. Artificial intelligence arrive...\n",
       "10    Artificial Intelligence is no match for Natura...\n",
       "11                              artificial intelligence\n",
       "12    @MrFresh LOL that explains the bug in Yar's Ar...\n",
       "13    aibits: Is mathematics the new artificial inte...\n",
       "14    You are a real boy. At least as real as I've e...\n",
       "15      Taking a break from my artificial intelligence.\n",
       "16    The a posteriori probability of Artificial Int...\n",
       "17    Oh boy... Just added \"Paradigms of Artificial ...\n",
       "18    NPR: Artificial Intelligence Enters Brave New ...\n",
       "19    It's really different...john is an AI  artific...\n",
       "20    Just finished watching Artificial Intelligence...\n",
       "21    Reading: \"OpenAi - - Creating the standard for...\n",
       "22    Reading: \"MachineBrain Robots, Robotics, Artif...\n",
       "23    reading \"Artificial Intelligence: a modern app...\n",
       "24    Working on artificial intelligence expert syst...\n",
       "Name: tweet_text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original tweet text for first 25 'all_years' tweets\n",
    "all_years.tweet_text[0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many 'all_years' tweets mention natural stupidity?\n",
    "len([tweet for tweet in all_years['tweet_text'] if 'natural stupidity' in tweet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: anyone involved work specifically anyone know any system that can recognise puns natural language\n",
      "1: paradigms programming case studies common lisp\n",
      "2: update geekgirl love and sex with robots advances cont\n",
      "3: speilberg movie based brian aldiss short story very creepy like better than robot\n",
      "4: paradigms programming\n",
      "5: chill dude your twirly brain wave patterns are fucking with the lesbian sexbot orbs production line\n",
      "6: leadership and two new issues shrinkrapradio were published shortly one aft\n",
      "7: class intro and computer simulation official grade yay\n",
      "8: aibits for advanced problem solving techniques\n",
      "9: most excellent arrives pick your pocket course truly human\n",
      "10: match for natural stupidity essa esta agora colada meu monitor\n",
      "11: \n",
      "12: lol that elains the bug yar module will have upgrade the irobot version\n",
      "13: aibits mathematics the new\n",
      "14: you are real boy least real ever made one\n",
      "15: taking break from\n",
      "16: the posteriori probability involving lot probability\n",
      "17: boy just added paradigms programming case studies common lisp amazon wish list\n",
      "18: npr enters brave new world\n",
      "19: really different john robot\n",
      "20: just finished watching thought was supposed happy movie not leave brawling eyes out\n",
      "21: reading openai creating the standard for\n",
      "22: reading machinebrain robots robotics and kits\n",
      "23: reading modern approach from stuart russell and peter norvig spectacular\n",
      "24: working eert system pretty much done\n"
     ]
    }
   ],
   "source": [
    "# cleaned text for first 25 'all_years' tweets\n",
    "search_words = ['artificial', 'intelligence', 'ai']\n",
    "\n",
    "for i, tweet in enumerate(all_years.tweet_text[0:25]):\n",
    "    print(i, ': ', clean_tweet(tweet, search_words), sep = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5460, 4) (10299, 4)\n"
     ]
    }
   ],
   "source": [
    "# clean the tweet text for both the 'all_years' and 'large_2019' tweets\n",
    "all_years_clean = all_years.copy()\n",
    "large_2019_clean = large_2019.copy()\n",
    "\n",
    "all_years_clean['tweet_text'] = [clean_tweet(tweet, search_words) for tweet in all_years['tweet_text']]\n",
    "large_2019_clean['tweet_text'] = [clean_tweet(tweet, search_words) for tweet in large_2019['tweet_text']]\n",
    "\n",
    "#all_years_clean = all_years_clean.drop_duplicates(subset = 'tweet_text')\n",
    "large_2019_clean = large_2019_clean.drop_duplicates(subset = 'tweet_text')  # many duplicate 'retweets'\n",
    "\n",
    "print(all_years_clean.shape, large_2019_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the cleaned tweets\n",
    "all_years_clean.to_pickle('all_years_clean.pickle')\n",
    "large_2019_clean.to_pickle('large_2019_clean.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
